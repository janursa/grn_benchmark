{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import scipy\n",
    "import decoupler as dc\n",
    "import seaborn as sns\n",
    "import json\n",
    "from scipy.sparse import csr_matrix\n",
    "from venn import venn # https://github.com/LankyCyril/pyvenn/blob/master/pyvenn-demo.ipynb\n",
    "\n",
    "surragate_names = {'collectRI':'CollectRI', 'collectRI_sign':'CollectRI-signs',\n",
    "                   'sp_grn':'Scenic+', 'sp_ct':'Scenic+', 'sp_grn_sign': 'Scenic+-signs',\n",
    "                   'co_grn':'CellOracle', 'co_ct':'CellOracle', 'co_grn_sign':'CellOracle-signs',\n",
    "                   'figr_grn':'FigR', 'figr_ct':'FigR', 'figr_grn_sign':'FigR-signs',\n",
    "                   'baseline':'Baseline'\n",
    "                   }\n",
    "\n",
    "%matplotlib inline\n",
    "work_dir = '../output'\n",
    "kaggle_data_dir = '../input/kaggle/input'\n",
    "os.makedirs(f'{work_dir}', exist_ok=True)\n",
    "\n",
    "train_cell_types = ['T cells CD4+', 'NK cells', 'T regulatory cells', 'T cells CD8+']\n",
    "test_celltypes = ['B cells', 'Myeloid cells'] \n",
    "agg_type = ['T regulatory cells', 'T cells CD8+', 'T cells CD4+']\n",
    "all_cell_types = ['T cells CD4+', 'NK cells', 'T regulatory cells', 'T cells CD8+', 'B cells', 'Myeloid cells']\n",
    "\n",
    "def calculate_p_values(genes, df):\n",
    "    '''\n",
    "    We conduct a 1-sample Kolmogorov-Smirnov (KS) test to detemine p-values for each given gene versus a uniform set.\n",
    "    Taken from Antoine Passiemier.\n",
    "    '''\n",
    "    p_values = []\n",
    "    for k, gene in tqdm.tqdm(enumerate(genes)):  # Perform test for each gene\n",
    "        v = df.iloc[:, k].values\n",
    "        v_valid = v[~np.isnan(v)]\n",
    "        if len(v_valid)<10:\n",
    "            raise ValueError('shouldnt be')\n",
    "        else:\n",
    "            v_valid = 10 ** (-np.abs(v_valid))  # Transform DE values to p-values (assumed to be uniformly-distributed)\n",
    "            res = scipy.stats.mstats.ks_1samp(v_valid, scipy.stats.uniform.cdf)  # Kolmogorov-Smirnov test\n",
    "            p_value = res[1]\n",
    "        p_values.append(p_value)\n",
    "    p_values = np.asarray(p_values)\n",
    "    return p_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_train = pd.read_parquet(f'{kaggle_data_dir}/open-problems-single-cell-perturbations/de_train.parquet')\n",
    "data_df = de_train.iloc[:,5:]\n",
    "data_df['cell_type'] = de_train['cell_type']\n",
    "data_df['sm_name'] = de_train['sm_name']\n",
    "data_df = data_df.set_index(['cell_type','sm_name'])\n",
    "data = data_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = True\n",
    "\n",
    "cv_scheme = 'sm_name_10' # 'cell_type', 'sm_name', '10cv', 'sm_name_10'\n",
    "metric_type = 'r2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of sparsity: 0.0\n",
      "ratio of sig: 0.12872298430075105\n"
     ]
    }
   ],
   "source": [
    "if original_data:\n",
    "    df_main_reg = pd.read_csv('../output/postprocess/EDA/data_df.csv', index_col=0).set_index(['cell_type', 'sm_name'])\n",
    "else:\n",
    "    df_main_reg = pd.read_csv('../output/postprocess/EDA/data_df_f.csv', index_col=0).set_index(['cell_type', 'sm_name'])\n",
    "real_values_mask = ~df_main_reg.isna()\n",
    "print('ratio of sparsity:', 1-real_values_mask.sum().sum()/real_values_mask.size)\n",
    "sig_mask = sig_mask = 10 ** (-np.abs(df_main_reg)) < 0.05\n",
    "print('ratio of sig:', sig_mask.sum().sum()/sig_mask.size)\n",
    "# set those nans to zero\n",
    "df_main_reg.isna().sum().sum()/df_main_reg.size\n",
    "df_main_reg.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder model and enrichment scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_tfs_single(df_main_c, net):\n",
    "    tf_act, p_values = dc.run_ulm(\n",
    "                df_main_c,\n",
    "                net,\n",
    "                source='source',\n",
    "                target='target',\n",
    "                weight='weight',\n",
    "                verbose=True\n",
    "                )\n",
    "    # tf_act = tf_act.set_index(df_main.index, drop=True)\n",
    "    return tf_act\n",
    "def enrich_tfs(df_main, net):\n",
    "    \"TF enrichment score cell specific grns\"\n",
    "    df_main_c = df_main.copy()\n",
    "    df_main_c.index = df_main.index.map(lambda x: '@'.join(map(str, x))) # this is needed for enrichment analyisis\n",
    "    if 'cell_type' in net:\n",
    "        cell_type_index = df_main.index.get_level_values('cell_type')\n",
    "        # EA for each cell type\n",
    "        tf_act_stack = []\n",
    "        for cell_type in net.cell_type.unique():\n",
    "            if cell_type == 'agg_type':\n",
    "                mask = cell_type_index.isin(agg_type)\n",
    "            else:\n",
    "                mask = cell_type_index==cell_type\n",
    "            df_main_celltype = df_main_c[mask]\n",
    "\n",
    "            net_celltype = net[net.cell_type==cell_type]\n",
    "            tf_act = enrich_tfs_single(df_main_celltype, net_celltype)\n",
    "            tf_act_stack.append(tf_act)\n",
    "        tf_act_df = pd.concat(tf_act_stack).fillna(0)\n",
    "        tf_act_df = tf_act_df.reindex(df_main_c.index)\n",
    "            \n",
    "    else:\n",
    "        tf_act_df = enrich_tfs_single(df_main_c, net)\n",
    "    return tf_act_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import decoupler as dc\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut, KFold\n",
    "\n",
    "random_state = 32\n",
    "id_map = pd.read_csv(f'{kaggle_data_dir}/open-problems-single-cell-perturbations/id_map.csv', index_col=0)\n",
    "\n",
    "class model_encoder:\n",
    "    def __init__(self, df_main, n_components=35, shares={\n",
    "                                        'sm_name':{'de_x':35},\n",
    "                                        'cell_type': {'de_x':6}\n",
    "                                        },\n",
    "                                        te_params = dict(min_samples_leaf=20, smoothing=100),\n",
    "                                        grn_model=None\n",
    "                                        ):  \n",
    "        # target df to encode\n",
    "        self.df_main = df_main\n",
    "        self.grn_model = grn_model\n",
    "        # regressor\n",
    "        self.emb_model = RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
    "        # reducer\n",
    "        self.reducer = TruncatedSVD(n_components=n_components, n_iter=12, random_state=random_state)\n",
    "        self.Y = self.reducer.fit_transform(df_main)\n",
    "        # encoder \n",
    "        self.enc = ce.TargetEncoder(**te_params) #[0, 0.05, 0.5, 0.1,0.9,10]\n",
    "        # encode data\n",
    "        var_x_name = list(shares['sm_name'].keys())[0]\n",
    "        n_components = shares['sm_name'][var_x_name]\n",
    "        y_sm_name = self.create_feature_space(self.df_main, var_x=var_x_name, n=n_components)\n",
    "        \n",
    "        # cell type\n",
    "        var_x_name = list(shares['cell_type'].keys())[0]\n",
    "        n_components = shares['cell_type'][var_x_name]\n",
    "        y_cell_type = self.create_feature_space(self.df_main, var_x=var_x_name, n=n_components)\n",
    "        # the order is important\n",
    "        self.emb_data = {'sm_name':y_sm_name, 'cell_type': y_cell_type}\n",
    "        self.determine_X()\n",
    "        print(self.X.shape, self.X_submit.shape)\n",
    "\n",
    "    def determine_X(self):\n",
    "        for i, (name, feature_x) in enumerate(self.emb_data.items()):\n",
    "            for i_target in tqdm.tqdm(range(feature_x.shape[1])):\n",
    "                if i_target == 0:\n",
    "                    # print(feature_x[:,i_target])\n",
    "                    X_encoded = self.enc.fit_transform(self.df_main.reset_index()[name], feature_x[:,i_target])\n",
    "                    X_submit_encoded = self.enc.transform(id_map.reset_index()[name])\n",
    "                else:\n",
    "                    X_encoded_tmp = self.enc.fit_transform(self.df_main.reset_index()[name], feature_x[:,i_target])\n",
    "                    X_encoded = np.concatenate( [X_encoded, X_encoded_tmp], axis = 1)\n",
    "                    X_encoded_tmp = self.enc.transform(id_map.reset_index()[name])\n",
    "                    X_submit_encoded = np.concatenate([X_submit_encoded, X_encoded_tmp], axis = 1)\n",
    "            if i == 0:\n",
    "                X = X_encoded\n",
    "                X_submit = X_submit_encoded\n",
    "            else:\n",
    "                X = np.concatenate([X, X_encoded], axis = 1)\n",
    "                X_submit = np.concatenate([X_submit, X_submit_encoded], axis = 1)\n",
    "\n",
    "        self.X = X\n",
    "        self.X_submit = X_submit\n",
    "    def create_feature_space(self, df_to_encode, var_x='sm_name', n=35):\n",
    "        if var_x == 'de_x':\n",
    "            return TruncatedSVD(n_components=n, n_iter=12, random_state=random_state).fit_transform(df_to_encode.values)\n",
    "\n",
    "        elif var_x == 'tf_x':\n",
    "            df_main_c = df_to_encode.copy()\n",
    "            net = self.grn_model\n",
    "            tf_act = enrich_tfs(df_main_c, net)\n",
    "\n",
    "            # tf_act = TruncatedSVD(n_components=n, n_iter=12, random_state=random_state).fit_transform(tf_act)\n",
    "            tf_act = tf_act.values\n",
    "            return tf_act\n",
    "        raise ValueError('define feature space')\n",
    "    def validate(self, mask_tr, mask_va):\n",
    "        # print(mask_tr)\n",
    "        X_tr, Y_tr = self.X[mask_tr,:], self.Y[mask_tr,:]\n",
    "        X_va = self.X[mask_va,:]\n",
    "        self.emb_model.fit(X_tr, Y_tr)\n",
    "        return self.reducer.inverse_transform(self.emb_model.predict(X_va))\n",
    "    def calculate_y_submit(self):\n",
    "        self.emb_model.fit(self.X, self.Y)\n",
    "        return self.reducer.inverse_transform(self.emb_model.predict(self.X_submit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load inferred GRNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grn_model_names = [\"collectRI\", \"figr_grn\", \"co_grn\", \"sp_grn\"]\n",
    "# grn_model_names = [\"sp_grn\"]\n",
    "grn_models_dict = {}\n",
    "for name in grn_model_names:\n",
    "    grn_models_dict[name] = pd.read_csv(f'../output/postprocess/grn_models/{name}.csv', index_col=0)\n",
    "grn_models_signs_dict = {}\n",
    "for name in grn_model_names:\n",
    "    name = f'{name}_sign'\n",
    "    grn_models_signs_dict[name] = pd.read_csv(f'../output/postprocess/grn_models/{name}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grn_models_shuffled_dict = {}\n",
    "for name, grn in grn_models_dict.items():\n",
    "    grn_s = grn.copy()\n",
    "    # grn_s['source'] = grn_s['source'].sample(frac=1).reset_index(drop=True)\n",
    "    grn_s['target'] = grn_s['target'].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    dup_flags = grn_s[['source','target']].duplicated()\n",
    "    grn_s = grn_s[~dup_flags].reset_index(drop=True)\n",
    "    if grn_s.duplicated().sum()>0:\n",
    "        raise ValueError('')\n",
    "    name = f'{name}_shuffled'\n",
    "    grn_models_shuffled_dict[name] = grn_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['collectRI', 'figr_grn', 'co_grn', 'sp_grn', 'collectRI_sign', 'figr_grn_sign', 'co_grn_sign', 'sp_grn_sign', 'collectRI_shuffled', 'figr_grn_shuffled', 'co_grn_shuffled', 'sp_grn_shuffled'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grn_models_all_dict = grn_models_dict | grn_models_signs_dict \n",
    "# grn_models_all_dict = grn_models_signs_dict | grn_models_shuffled_dict\n",
    "grn_models_all_dict = grn_models_dict | grn_models_signs_dict | grn_models_shuffled_dict\n",
    "# del grn_models_all_dict['collectRI_sign']\n",
    "grn_models_all_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of SVDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- collectRI\n",
      "Running ulm on mat with 614 samples and 18211 targets for 632 sources.\n",
      "Number of components to retain 0.9 of the variance: 132\n",
      "---- figr_grn\n",
      "Running ulm on mat with 614 samples and 18211 targets for 727 sources.\n",
      "Number of components to retain 0.9 of the variance: 246\n",
      "---- co_grn\n",
      "Running ulm on mat with 17 samples and 18211 targets for 504 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 520 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 503 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 479 sources.\n",
      "Number of components to retain 0.9 of the variance: 7\n",
      "---- sp_grn\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, grn \u001b[38;5;129;01min\u001b[39;00m grn_models_all_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----\u001b[39m\u001b[38;5;124m'\u001b[39m,name)\n\u001b[0;32m---> 19\u001b[0m     n_components_dict[name] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_svds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_main_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36mfunc_svds\u001b[0;34m(df, net, explained_variance_t)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine number of SVDs to explain 90% of varaince\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_main_c \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 6\u001b[0m tf_act \u001b[38;5;241m=\u001b[39m \u001b[43menrich_tfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_main_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(tf_act.iloc[0:3,:5])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m([\u001b[38;5;241m500\u001b[39m, tf_act\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]])\n",
      "Cell \u001b[0;32mIn[10], line 34\u001b[0m, in \u001b[0;36menrich_tfs\u001b[0;34m(df_main, net)\u001b[0m\n\u001b[1;32m     31\u001b[0m     tf_act_df \u001b[38;5;241m=\u001b[39m tf_act_df\u001b[38;5;241m.\u001b[39mreindex(df_main_c\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     tf_act_df \u001b[38;5;241m=\u001b[39m \u001b[43menrich_tfs_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_main_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf_act_df\n",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m, in \u001b[0;36menrich_tfs_single\u001b[0;34m(df_main_c, net)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menrich_tfs_single\u001b[39m(df_main_c, net):\n\u001b[0;32m----> 2\u001b[0m     tf_act, p_values \u001b[38;5;241m=\u001b[39m \u001b[43mdc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_ulm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdf_main_c\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# tf_act = tf_act.set_index(df_main.index, drop=True)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf_act\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/decoupler/method_ulm.py:105\u001b[0m, in \u001b[0;36mrun_ulm\u001b[0;34m(mat, net, source, target, weight, batch_size, min_n, verbose, use_raw)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mUnivariate Linear Model (ULM).\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Obtained p-values. Stored in `.obsm['ulm_pvals']` if `mat` is AnnData.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Extract sparse matrix and array of genes\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m m, r, c \u001b[38;5;241m=\u001b[39m \u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Transform net\u001b[39;00m\n\u001b[1;32m    108\u001b[0m net \u001b[38;5;241m=\u001b[39m rename_net(net, source\u001b[38;5;241m=\u001b[39msource, target\u001b[38;5;241m=\u001b[39mtarget, weight\u001b[38;5;241m=\u001b[39mweight)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/decoupler/pre.py:99\u001b[0m, in \u001b[0;36mextract\u001b[0;34m(mat, use_raw, verbose, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Sort genes\u001b[39;00m\n\u001b[1;32m     97\u001b[0m msk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(c)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m, r\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m'\u001b[39m), c[msk]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "def func_svds(df, net, explained_variance_t=0.9): \n",
    "    \"\"\"Determine number of SVDs to explain 90% of varaince\"\"\"\n",
    "    df_main_c = df.copy()\n",
    "    tf_act = enrich_tfs(df_main_c, net)\n",
    "    # print(tf_act.iloc[0:3,:5])\n",
    "    n_components = min([500, tf_act.shape[1]])\n",
    "    # reducer = TruncatedSVD(n_components=n_components, n_iter=10, random_state=32)\n",
    "    reducer = PCA(n_components=n_components, random_state=32) \n",
    "    reducer.fit(tf_act)\n",
    "    variance_explained = reducer.explained_variance_ratio_.cumsum()\n",
    "    n_components = sum(variance_explained < explained_variance_t) + 1  # Number of components to capture 90% variance\n",
    "    print(f\"Number of components to retain {explained_variance_t} of the variance: {n_components}\")\n",
    "    return n_components\n",
    "n_components_dict = {}\n",
    "for name, grn in grn_models_all_dict.items():\n",
    "    print('----',name)\n",
    "    n_components_dict[name] = func_svds(df_main_reg, grn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 614 samples and 18211 targets for 632 sources.\n",
      "Running ulm on mat with 614 samples and 18211 targets for 632 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 632/632 [00:12<00:00, 48.63it/s]\n",
      "100%|██████████| 632/632 [00:13<00:00, 47.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1264) (255, 1264)\n",
      "Running ulm on mat with 614 samples and 18211 targets for 727 sources.\n",
      "Running ulm on mat with 614 samples and 18211 targets for 727 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 727/727 [00:15<00:00, 45.89it/s]\n",
      " 27%|██▋       | 199/727 [00:04<00:11, 47.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m enc_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, grn \u001b[38;5;129;01min\u001b[39;00m grn_models_all_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 5\u001b[0m     enc_models[name] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_main_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrn_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshares\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msm_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# ababa\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 43\u001b[0m, in \u001b[0;36mmodel_encoder.__init__\u001b[0;34m(self, df_main, n_components, shares, te_params, grn_model)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# the order is important\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msm_name\u001b[39m\u001b[38;5;124m'\u001b[39m:y_sm_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m'\u001b[39m: y_cell_type}\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetermine_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_submit\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[16], line 54\u001b[0m, in \u001b[0;36mmodel_encoder.determine_X\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m     X_submit_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc\u001b[38;5;241m.\u001b[39mtransform(id_map\u001b[38;5;241m.\u001b[39mreset_index()[name])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     X_encoded_tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_main\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi_target\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     X_encoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate( [X_encoded, X_encoded_tmp], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     56\u001b[0m     X_encoded_tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc\u001b[38;5;241m.\u001b[39mtransform(id_map\u001b[38;5;241m.\u001b[39mreset_index()[name])\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/sklearn/utils/_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    279\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/category_encoders/utils.py:459\u001b[0m, in \u001b[0;36mSupervisedTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_transform() missing argument: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/category_encoders/utils.py:312\u001b[0m, in \u001b[0;36mBaseEncoder.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumns to be encoded can not contain null\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# for finding invariant columns transform without y (as is done on the test set)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(X, override_return_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/category_encoders/target_encoder.py:182\u001b[0m, in \u001b[0;36mTargetEncoder._fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     X_hier_ordinal \u001b[38;5;241m=\u001b[39m enc_hier\u001b[38;5;241m.\u001b[39mtransform(X_hier)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordinal_encoder \u001b[38;5;241m=\u001b[39m OrdinalEncoder(\n\u001b[1;32m    177\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    178\u001b[0m     cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols,\n\u001b[1;32m    179\u001b[0m     handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    180\u001b[0m     handle_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m )\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordinal_encoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordinal_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m X_ordinal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordinal_encoder\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhierarchy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/category_encoders/utils.py:312\u001b[0m, in \u001b[0;36mBaseEncoder.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumns to be encoded can not contain null\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# for finding invariant columns transform without y (as is done on the test set)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(X, override_return_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/category_encoders/ordinal.py:102\u001b[0m, in \u001b[0;36mOrdinalEncoder._fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping_supplied:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m _, categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordinal_encoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_missing\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping \u001b[38;5;241m=\u001b[39m categories\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/category_encoders/ordinal.py:238\u001b[0m, in \u001b[0;36mOrdinalEncoder.ordinal_encoding\u001b[0;34m(X_in, mapping, cols, handle_unknown, handle_missing)\u001b[0m\n\u001b[1;32m    234\u001b[0m         categories \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mnan]\n\u001b[1;32m    236\u001b[0m index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(categories)\u001b[38;5;241m.\u001b[39mfillna(nan_identity)\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m--> 238\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m~\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    241\u001b[0m     data\u001b[38;5;241m.\u001b[39mloc[nan_identity] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/series.py:509\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    507\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/construction.py:535\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    532\u001b[0m     data \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(data)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mrange\u001b[39m):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;66;03m# GH#16804\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mrange_to_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/construction.py:623\u001b[0m, in \u001b[0;36mrange_to_ndarray\u001b[0;34m(rng)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# GH#30171 perf avoid realizing range as a list in np.array\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 623\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;66;03m# GH#30173 handling for ranges that overflow int64\u001b[39;00m\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (rng\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m rng\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (rng\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mstop):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create encoding models \n",
    "enc_models = {}\n",
    "for name, grn in grn_models_all_dict.items():\n",
    "    \n",
    "    enc_models[name] = model_encoder(df_main_reg, grn_model=grn, shares={\n",
    "                                        'sm_name':{'tf_x':None},\n",
    "                                        'cell_type': {'tf_x':None}\n",
    "                                        })\n",
    "    # ababa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 40.17it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 46.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 41) (255, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## add baseline model. for subset gene study, we create one baseline per grn because the number of target genes are different from one grn to another\n",
    "enc_models['baseline'] = model_encoder(df_main_reg, shares={\n",
    "                                            'sm_name':{'de_x':35},\n",
    "                                            'cell_type': {'de_x':6}\n",
    "                                            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle score\n",
    "We can only submit if they are build on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "os.environ['KAGGLE_USERNAME'] = 'jalilnourisa'\n",
    "os.environ['KAGGLE_KEY'] = '63552f12403af36f40106e6821e80327'\n",
    "api = KaggleApi()\n",
    "api.authenticate() \n",
    "prefix = 'tfactivity_shuffled'    # group of runs. set this to something that tags your experiemnt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collectRI_shuffled\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.6 / client 1.5.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 12.3M/36.7M [00:18<00:27, 944kB/s]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:48<00:00, 791kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figr_grn_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.6M/36.6M [00:48<00:00, 791kB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co_grn_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:48<00:00, 791kB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_grn_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.8M/36.8M [00:48<00:00, 789kB/s]   \n"
     ]
    }
   ],
   "source": [
    "gene_names = df_main_reg.columns\n",
    "\n",
    "os.makedirs('../output/submits/', exist_ok=True)\n",
    "\n",
    "def format_y_submit(Y_submit):\n",
    "    y_submit_df = pd.DataFrame(Y_submit, columns=gene_names)\n",
    "    y_submit_df.index.name = 'id'\n",
    "    y_submit_df = y_submit_df.round(5)\n",
    "    return y_submit_df\n",
    "def write_submit(Y_submit_df, file_name):\n",
    "    Y_submit_df.to_csv(f'../output/submits/{file_name}.csv')\n",
    "def submit(file_name):\n",
    "    filename = f\"../output/submits/{file_name}.csv\"\n",
    "    competition = \"open-problems-single-cell-perturbations\"\n",
    "    api.competition_submit(file_name=filename, message=file_name, competition=competition)\n",
    "\n",
    "for name, model in enc_models.items():\n",
    "    # if name in ['collectRI','baseline', 'collectRI_sign']:\n",
    "    #     continue\n",
    "    file_name = f'{prefix}_{name}'\n",
    "    print(name)\n",
    "    y_submit = model.calculate_y_submit()\n",
    "    y_submit_df = format_y_submit(y_submit)\n",
    "    write_submit(y_submit_df, file_name)\n",
    "    submit(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggle scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaggle_scores(prefix):\n",
    "    submissions = api.competition_submissions(\"open-problems-single-cell-perturbations\")\n",
    "    kaggle_scores_dict = {}\n",
    "    for submission in submissions:\n",
    "        kaggle_scores_dict[submission.fileName.replace('.csv', '')] = [submission.publicScore,  submission.privateScore]\n",
    "    kaggle_scores_dict = {key:values for key,values in kaggle_scores_dict.items() if (prefix in key)}\n",
    "    kaggle_scores_df = pd.DataFrame(kaggle_scores_dict.values(), index=kaggle_scores_dict.keys(), columns=['public_test', 'private_test']).reset_index().rename(columns={'index':'grn_model'})\n",
    "    kaggle_scores_df.grn_model = kaggle_scores_df.grn_model.str.replace(f'{prefix}_','')\n",
    "    return kaggle_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grn_model</th>\n",
       "      <th>public_test</th>\n",
       "      <th>private_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp_grn_shuffled</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>co_grn_shuffled</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>figr_grn_shuffled</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>collectRI_shuffled</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            grn_model public_test private_test\n",
       "0     sp_grn_shuffled       0.613        0.791\n",
       "1     co_grn_shuffled       0.597        0.774\n",
       "2   figr_grn_shuffled        0.59        0.789\n",
       "3  collectRI_shuffled       0.598        0.768"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_scores_df = get_kaggle_scores(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grn_model</th>\n",
       "      <th>public_test</th>\n",
       "      <th>private_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp_grn_sign</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>co_grn_sign</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>figr_grn_sign</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp_grn</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>co_grn</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>figr_grn</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>collectRI</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       grn_model public_test private_test\n",
       "0    sp_grn_sign       0.614         0.77\n",
       "1    co_grn_sign       0.602        0.774\n",
       "2  figr_grn_sign       0.597        0.767\n",
       "3         sp_grn       0.599        0.788\n",
       "4         co_grn       0.594        0.789\n",
       "5       figr_grn       0.595        0.766\n",
       "6      collectRI       0.602        0.769"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "if metric_type=='MSE':\n",
    "    error_metric = lambda y_pred, y_true: mean_absolute_error(y_pred, y_true)\n",
    "elif metric_type=='r2':\n",
    "    error_metric = lambda y_pred, y_true: r2_score(y_pred, y_true)\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import r2_score\n",
    "# define groups \n",
    "if cv_scheme=='sm_name': # cluster of sm_name\n",
    "    sm_names = df_main_reg.index.get_level_values('sm_name')\n",
    "    unique_sm_names = sm_names.unique()\n",
    "    group_assignments = range(len(unique_sm_names))\n",
    "    group_dict = dict(zip(unique_sm_names, group_assignments))\n",
    "    groups = sm_names.map(group_dict)\n",
    "elif cv_scheme=='sm_name_10': # cluster of sm_name\n",
    "    n = 10\n",
    "    sm_names = df_main_reg.index.get_level_values('sm_name')\n",
    "    unique_sm_names = sm_names.unique().values\n",
    "    group_assignments = range(n)\n",
    "    np.random.shuffle(unique_sm_names)\n",
    "    group_dict = {}\n",
    "    for i, sm_name in enumerate(unique_sm_names):\n",
    "        group_dict[sm_name] = i%n\n",
    "    groups = sm_names.map(group_dict)\n",
    "elif cv_scheme=='cell_type': # one group for each trainig cell_type\n",
    "    cell_types = df_main_reg.index.get_level_values('cell_type')\n",
    "    train_cell_types = ['NK cells', 'T cells CD4+', 'T cells CD8+', 'T regulatory cells']\n",
    "    group_assignments = range(len(train_cell_types))\n",
    "    group_dict = dict(zip(train_cell_types, group_assignments))\n",
    "    groups = cell_types.map(group_dict)\n",
    "elif cv_scheme=='10cv':\n",
    "    num_groups = 10\n",
    "    group_assignments = range(num_groups)\n",
    "    group_size = len(df_main_reg) // num_groups\n",
    "    groups = np.repeat(np.arange(num_groups), group_size)\n",
    "    if len(df_main_reg) % num_groups != 0:\n",
    "        groups = np.concatenate((groups, np.arange(len(df_main_reg) % num_groups)))\n",
    "    np.random.shuffle(groups)\n",
    "else:\n",
    "    raise ValueError('define')\n",
    "\n",
    "def compute_cv_raw(model, df_main_reg):\n",
    "    y_true_list = []\n",
    "    y_pred_list = [] \n",
    "    for group in tqdm.tqdm(group_assignments):\n",
    "        mask_va = groups==group\n",
    "        mask_tr = groups!=group\n",
    "        y_true = df_main_reg[mask_va]\n",
    "        y_pred = pd.DataFrame(model.validate(mask_tr, mask_va), index=y_true.index, columns=y_true.columns)\n",
    "        # evaluate only those that are sig and also non imputed\n",
    "        real_values = real_values_mask[mask_va] \n",
    "        \n",
    "        group_mask = real_values\n",
    "\n",
    "        y_true = y_true[group_mask]\n",
    "        y_pred = y_pred[group_mask]\n",
    "        \n",
    "        y_pred = y_pred.reset_index()\n",
    "        y_pred['group'] = group\n",
    "        y_pred_list.append(y_pred)\n",
    "\n",
    "        y_true = y_true.reset_index()\n",
    "        y_true['group'] = group\n",
    "        y_true_list.append(y_true)\n",
    "    y_pred_df = pd.concat(y_pred_list).reset_index(drop=True)\n",
    "    y_true_df = pd.concat(y_true_list).reset_index(drop=True)\n",
    "    return y_pred_df, y_true_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- collectRI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:09<00:00, 24.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29847007933264735\n",
      "---- figr_grn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:55<00:00, 29.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22158774519683688\n",
      "---- co_grn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:25<00:00, 20.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30067948130563227\n",
      "---- sp_grn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:32<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.280540622049124\n",
      "---- figr_grn_sign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:02<00:00, 30.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20600421980247985\n",
      "---- co_grn_sign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:13<00:00, 25.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36731856616681713\n",
      "---- sp_grn_sign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22382029724542352\n",
      "---- collectRI_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:26<00:00, 32.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25812516530071417\n",
      "---- figr_grn_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:14<00:00, 37.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19975416992511041\n",
      "---- co_grn_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:15<00:00, 25.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3488416282450282\n",
      "---- sp_grn_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:45<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18264536141947096\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "fresh_start = True\n",
    "\n",
    "# fresh start or load the cv results partly done\n",
    "cv_scores_dict = {}\n",
    "if fresh_start: #fresh start\n",
    "    cv_scores_genes_dict = {}\n",
    "else: # warm start\n",
    "    with open(f'../output/postprocess/CV/cv_scores_genes_dict_{original_data}_{only_sig_de}_{subset_genes}.json', 'r') as file:\n",
    "        cv_scores_genes_dict = json.load(file)\n",
    "# del cv_scores_genes_dict['collectRI_figr_union_grn']\n",
    "for name, model in enc_models.items():\n",
    "    if name in list(cv_scores_genes_dict.keys()):\n",
    "        continue\n",
    "    elif name in ['collectRI_sign']:\n",
    "        continue\n",
    "    print('----',name)\n",
    "    \n",
    "    ## --- calculate mean score \n",
    "    # get y pred and y true for all cv groups\n",
    "    y_pred_df, y_true_df = compute_cv_raw(model, df_main_reg)\n",
    "    # melt them into arrays\n",
    "    y_pred_values = y_pred_df[df_main_reg.columns].melt().value.values\n",
    "    y_true_values = y_true_df[df_main_reg.columns].melt().value.values\n",
    "    # nan check\n",
    "    nan_mask = np.isnan(y_true_values)\n",
    "    y_true_values = y_true_values[~nan_mask]\n",
    "    y_pred_values = y_pred_values[~nan_mask]\n",
    "    # zero check\n",
    "    zero_mask = y_true_values==0\n",
    "    y_true_values = y_true_values[~zero_mask]\n",
    "    y_pred_values = y_pred_values[~zero_mask]\n",
    "    cv_score = error_metric(y_true_values, y_pred_values)\n",
    "    print(cv_score)\n",
    "    cv_scores_dict[name] = cv_score\n",
    "    \n",
    "    ## --- calculate gene wise score\n",
    "    r2_scores_genes = []\n",
    "    for gene in df_main_reg.columns:\n",
    "        y_true = y_true_df[gene].values\n",
    "        y_pred = y_pred_df[gene].values\n",
    "\n",
    "        nan_mask = np.isnan(y_true)\n",
    "\n",
    "        y_true = y_true[~nan_mask]\n",
    "        y_pred = y_pred[~nan_mask]\n",
    "\n",
    "        zero_mask = y_true==0\n",
    "\n",
    "        y_true = y_true[~zero_mask]\n",
    "        y_pred = y_pred[~zero_mask]\n",
    "        if len(y_true)<5:\n",
    "            # print(gene, 'insufficient samples')\n",
    "            r2_score_case = np.nan\n",
    "        else:\n",
    "            y_mean = y_true.mean()\n",
    "            \n",
    "            total_sum_of_squares = ((y_true - y_mean) ** 2).sum()\n",
    "            sum_of_squares_of_residuals = ((y_true - y_pred) ** 2).sum()\n",
    "            \n",
    "            r2_score_case = 1 - (sum_of_squares_of_residuals / total_sum_of_squares)\n",
    "        r2_scores_genes.append(r2_score_case)\n",
    "    r2_scores_genes = np.asarray(r2_scores_genes)\n",
    "    cv_scores_genes_dict[name] = list(r2_scores_genes)\n",
    "\n",
    "    with open(f'../output/postprocess/CV/cv_scores_genes_dict_{original_data}.json', 'w') as file:\n",
    "        json.dump(cv_scores_genes_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collectRI': 0.29847007933264735,\n",
       " 'figr_grn': 0.22158774519683688,\n",
       " 'co_grn': 0.30067948130563227,\n",
       " 'sp_grn': 0.280540622049124,\n",
       " 'figr_grn_sign': 0.20600421980247985,\n",
       " 'co_grn_sign': 0.36731856616681713,\n",
       " 'sp_grn_sign': 0.22382029724542352,\n",
       " 'collectRI_shuffled': 0.25812516530071417,\n",
       " 'figr_grn_shuffled': 0.19975416992511041,\n",
       " 'co_grn_shuffled': 0.3488416282450282,\n",
       " 'sp_grn_shuffled': 0.18264536141947096}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool the predictions\n",
    "y_submits = []\n",
    "for name, enc_model in tqdm.tqdm(enc_models.items()):\n",
    "    y_submits.append(enc_model.calculate_y_submit())\n",
    "pool_ = np.concatenate([np.ndarray.flatten(y_submit) for y_submit in y_submits])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit_format = format_y_submit(y_submits[0])\n",
    "y_submits_random = []\n",
    "for i in range(100):\n",
    "    y_submits_random.append(format_y_submit(np.random.choice(pool_, size=y_submit_format.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.6 / client 1.5.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [01:01<00:00, 624kB/s] \n",
      "100%|██████████| 36.7M/36.7M [00:55<00:00, 690kB/s] \n",
      "100%|██████████| 36.7M/36.7M [01:18<00:00, 488kB/s] \n",
      "100%|██████████| 36.7M/36.7M [00:58<00:00, 658kB/s] \n",
      "100%|██████████| 36.7M/36.7M [00:57<00:00, 670kB/s] \n",
      "100%|██████████| 36.7M/36.7M [01:10<00:00, 547kB/s] \n",
      "100%|██████████| 36.7M/36.7M [01:02<00:00, 615kB/s] \n",
      "100%|██████████| 36.7M/36.7M [00:56<00:00, 687kB/s] \n",
      "100%|██████████| 36.7M/36.7M [00:54<00:00, 703kB/s] \n",
      "100%|██████████| 36.7M/36.7M [00:59<00:00, 643kB/s] \n",
      "100%|██████████| 36.7M/36.7M [00:57<00:00, 673kB/s] \n",
      "100%|██████████| 36.7M/36.7M [01:14<00:00, 520kB/s] \n",
      "100%|██████████| 36.7M/36.7M [01:15<00:00, 509kB/s] \n",
      "100%|██████████| 36.7M/36.7M [01:30<00:00, 426kB/s] \n",
      "100%|██████████| 36.7M/36.7M [01:22<00:00, 465kB/s]   \n",
      "100%|██████████| 36.7M/36.7M [01:04<00:00, 600kB/s]   \n",
      "100%|██████████| 36.7M/36.7M [01:03<00:00, 611kB/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, y_submit_df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_submits_random):\n\u001b[1;32m      9\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mwrite_submit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_submit_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     submit(file_name)\n",
      "Cell \u001b[0;32mIn[137], line 11\u001b[0m, in \u001b[0;36mwrite_submit\u001b[0;34m(Y_submit_df, file_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_submit\u001b[39m(Y_submit_df, file_name):\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mY_submit_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../output/submits/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/io/formats/csvs.py:309\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    306\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[1;32m    307\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[0;32m--> 309\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_native_types\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    312\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/internals/managers.py:512\u001b[0m, in \u001b[0;36mBaseBlockManager.to_native_types\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_native_types\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    508\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mto_native_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/internals/blocks.py:531\u001b[0m, in \u001b[0;36mBlock.to_native_types\u001b[0;34m(self, na_rep, quoting, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_native_types\u001b[39m(\u001b[38;5;28mself\u001b[39m, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[1;32m    530\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[0;32m--> 531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mto_native_types\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/internals/blocks.py:2538\u001b[0m, in \u001b[0;36mto_native_types\u001b[0;34m(values, na_rep, quoting, float_format, decimal, **kwargs)\u001b[0m\n\u001b[1;32m   2535\u001b[0m mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quoting:\n\u001b[0;32m-> 2538\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2540\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "os.environ['KAGGLE_USERNAME'] = 'jalilnourisa'\n",
    "os.environ['KAGGLE_KEY'] = '63552f12403af36f40106e6821e80327'\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "prefix = 'random'    \n",
    "\n",
    "for i, y_submit_df in enumerate(y_submits_random):\n",
    "    if i < 17:\n",
    "        continue\n",
    "    file_name = f'{prefix}_{i}'\n",
    "    write_submit(y_submit_df, file_name)\n",
    "    submit(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grn_model</th>\n",
       "      <th>public_test</th>\n",
       "      <th>private_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.898</td>\n",
       "      <td>1.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.899</td>\n",
       "      <td>1.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.898</td>\n",
       "      <td>1.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>0.899</td>\n",
       "      <td>1.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0.898</td>\n",
       "      <td>1.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grn_model public_test private_test\n",
       "0         16                         \n",
       "1         15       0.901        1.289\n",
       "2         14       0.898        1.291\n",
       "3         13       0.895        1.286\n",
       "4         12       0.897        1.286\n",
       "5         11       0.897        1.286\n",
       "6         10       0.899        1.289\n",
       "7          9       0.897        1.286\n",
       "8          8       0.898        1.287\n",
       "9          7       0.897        1.282\n",
       "10         6       0.897        1.286\n",
       "11         5       0.896        1.284\n",
       "12         4       0.899        1.286\n",
       "13         3       0.897        1.285\n",
       "14         2       0.898        1.282\n",
       "15         1       0.896        1.284\n",
       "16         0       0.897        1.285"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle grn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffletest_co_grn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:46<00:00, 833kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 522 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 522 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 553/553 [00:14<00:00, 39.02it/s]\n",
      "100%|██████████| 553/553 [00:13<00:00, 39.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1106) (255, 1106)\n",
      "shuffletest_co_grn_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:47<00:00, 806kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 535 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 532 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 522 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 535 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 532 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 522 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 554/554 [00:14<00:00, 38.28it/s]\n",
      "100%|██████████| 554/554 [00:13<00:00, 40.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1108) (255, 1108)\n",
      "shuffletest_co_grn_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.8M/36.8M [00:47<00:00, 816kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 530 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 558/558 [00:14<00:00, 38.79it/s]\n",
      "100%|██████████| 558/558 [00:12<00:00, 44.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1116) (255, 1116)\n",
      "shuffletest_co_grn_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:46<00:00, 833kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 529 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 552/552 [00:12<00:00, 43.53it/s]\n",
      "100%|██████████| 552/552 [00:12<00:00, 43.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1104) (255, 1104)\n",
      "shuffletest_co_grn_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:45<00:00, 845kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 530 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 554/554 [00:12<00:00, 44.27it/s]\n",
      "100%|██████████| 554/554 [00:12<00:00, 44.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1108) (255, 1108)\n",
      "shuffletest_co_grn_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:44<00:00, 857kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 533 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 553/553 [00:12<00:00, 44.49it/s]\n",
      "100%|██████████| 553/553 [00:12<00:00, 45.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1106) (255, 1106)\n",
      "shuffletest_co_grn_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:45<00:00, 848kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 532 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 532 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 554/554 [00:13<00:00, 41.83it/s]\n",
      "100%|██████████| 554/554 [00:12<00:00, 44.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1108) (255, 1108)\n",
      "shuffletest_co_grn_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:45<00:00, 850kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 531 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:12<00:00, 45.36it/s]\n",
      "100%|██████████| 555/555 [00:12<00:00, 45.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1110) (255, 1110)\n",
      "shuffletest_co_grn_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:45<00:00, 846kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 527 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 522 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 523 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 527 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 522 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 523 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 551/551 [00:12<00:00, 42.75it/s]\n",
      "100%|██████████| 551/551 [00:12<00:00, 43.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1102) (255, 1102)\n",
      "shuffletest_co_grn_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.8M/36.8M [00:45<00:00, 844kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 535 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 535 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 530 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 559/559 [00:12<00:00, 44.34it/s]\n",
      "100%|██████████| 559/559 [00:12<00:00, 44.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1118) (255, 1118)\n",
      "shuffletest_co_grn_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:46<00:00, 833kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 529 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 554/554 [00:13<00:00, 40.99it/s]\n",
      "100%|██████████| 554/554 [00:14<00:00, 38.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1108) (255, 1108)\n",
      "shuffletest_co_grn_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:45<00:00, 849kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 534 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 534 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 531 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 554/554 [00:13<00:00, 41.05it/s]\n",
      "100%|██████████| 554/554 [00:13<00:00, 40.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1108) (255, 1108)\n",
      "shuffletest_co_grn_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:46<00:00, 825kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 522 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 525 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 522 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 528 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 556/556 [00:14<00:00, 38.37it/s]\n",
      "100%|██████████| 556/556 [00:14<00:00, 39.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1112) (255, 1112)\n",
      "shuffletest_co_grn_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:45<00:00, 841kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 527 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 532 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 527 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 532 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 553/553 [00:13<00:00, 39.95it/s]\n",
      "100%|██████████| 553/553 [00:13<00:00, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1106) (255, 1106)\n",
      "shuffletest_co_grn_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.8M/36.8M [00:46<00:00, 830kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 523 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 523 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 530 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:14<00:00, 38.63it/s]\n",
      "100%|██████████| 555/555 [00:13<00:00, 39.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1110) (255, 1110)\n",
      "shuffletest_co_grn_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.8M/36.8M [00:45<00:00, 845kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 527 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 530 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 527 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:13<00:00, 40.21it/s]\n",
      "100%|██████████| 555/555 [00:13<00:00, 40.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1110) (255, 1110)\n",
      "shuffletest_co_grn_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:47<00:00, 811kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 533 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 531 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 529 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:14<00:00, 39.16it/s]\n",
      "100%|██████████| 555/555 [00:15<00:00, 35.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1110) (255, 1110)\n",
      "shuffletest_co_grn_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:45<00:00, 844kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 532 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 526 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 528 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 532 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 528 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 556/556 [00:13<00:00, 41.05it/s]\n",
      "100%|██████████| 556/556 [00:13<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1112) (255, 1112)\n",
      "shuffletest_co_grn_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:46<00:00, 822kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 534 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 527 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 534 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 534 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 527 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 524 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 534 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 554/554 [00:13<00:00, 40.99it/s]\n",
      "100%|██████████| 554/554 [00:13<00:00, 41.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1108) (255, 1108)\n",
      "shuffletest_co_grn_18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.8M/36.8M [00:46<00:00, 836kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 17 samples and 18211 targets for 532 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 523 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 532 sources.\n",
      "Running ulm on mat with 17 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 146 samples and 18211 targets for 529 sources.\n",
      "Running ulm on mat with 434 samples and 18211 targets for 523 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 553/553 [00:16<00:00, 33.27it/s]\n",
      "100%|██████████| 553/553 [00:15<00:00, 36.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1106) (255, 1106)\n",
      "shuffletest_co_grn_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.7M/36.7M [00:46<00:00, 838kB/s] \n"
     ]
    }
   ],
   "source": [
    "prefix = 'shuffletest'\n",
    "for name, grn in zip(['co_grn'], [co_grn]):\n",
    "    file_name = f'{prefix}_{name}'\n",
    "    print(file_name)\n",
    "    y_submit = enc_model.calculate_y_submit()\n",
    "    y_submit_df = format_y_submit(y_submit)\n",
    "    write_submit(y_submit_df, file_name)\n",
    "    submit(file_name)\n",
    "\n",
    "    for i in range(0,20):\n",
    "        grn_s = grn.copy()\n",
    "        grn_s['source'] = grn_s['source'].sample(frac=1).reset_index(drop=True)\n",
    "        grn_s['target'] = grn_s['target'].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        dup_flags = grn_s[['source','target']].duplicated()\n",
    "        grn_s = grn_s[~dup_flags].reset_index(drop=True)\n",
    "        if grn_s.duplicated().sum()>0:\n",
    "            raise ValueError('')\n",
    "        #-- create the model\n",
    "        sm_name_svd_n = 35\n",
    "        celltype_svd_n = 6\n",
    "\n",
    "        enc_model = model_encoder(df_main_reg, grn_model=grn_s, shares={\n",
    "                                            'sm_name':{'tf_x':sm_name_svd_n},\n",
    "                                            'cell_type': {'tf_x':celltype_svd_n}\n",
    "                                            })\n",
    "        file_name = f'{prefix}_{name}_{i}'\n",
    "        print(file_name)\n",
    "        y_submit = enc_model.calculate_y_submit()\n",
    "        y_submit_df = format_y_submit(y_submit)\n",
    "        write_submit(y_submit_df, file_name)\n",
    "        submit(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.599 0.5954390243902439\n",
      "0.764 0.7741463414634147\n",
      "0.607 0.5952439024390244\n",
      "0.77 0.774\n"
     ]
    }
   ],
   "source": [
    "df = get_kaggle_scores(prefix)\n",
    "real  = df[df.grn_model=='figr_grn']\n",
    "rest = df[df.grn_model!='figr_grn']\n",
    "for score in ['public_test', 'private_test']:\n",
    "    # print(rest[score].astype(float).mean())\n",
    "    print(real[score].mean(), rest[score].astype(float).mean())\n",
    "\n",
    "# df = get_kaggle_scores(prefix)\n",
    "real  = df[df.grn_model=='co_grn']\n",
    "rest = df[df.grn_model!='co_grn']\n",
    "for score in ['public_test', 'private_test']:\n",
    "    # print(rest[score].astype(float).mean())\n",
    "    print(real[score].mean(), rest[score].astype(float).mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
