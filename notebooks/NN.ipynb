{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:39:31.191869Z",
     "iopub.status.busy": "2024-05-24T10:39:31.191471Z",
     "iopub.status.idle": "2024-05-24T10:39:40.610502Z",
     "shell.execute_reply": "2024-05-24T10:39:40.609797Z",
     "shell.execute_reply.started": "2024-05-24T10:39:31.191839Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "seed = 16\n",
    "use_gpu = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# df = pd.read_csv('df.csv', index_col=0)\n",
    "# data = df.values\n",
    "adata = ad.read_h5ad('../output/preprocess/bulk_adata_f.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = adata.layers['X_norm_pearson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grn_net_df = pd.read_csv(\"https://github.com/pablormier/omnipath-static/raw/main/op/collectri-26.09.2023.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:39:40.612142Z",
     "iopub.status.busy": "2024-05-24T10:39:40.611788Z",
     "iopub.status.idle": "2024-05-24T10:39:41.218809Z",
     "shell.execute_reply": "2024-05-24T10:39:41.218030Z",
     "shell.execute_reply.started": "2024-05-24T10:39:40.612114Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adata = ad.read_h5ad('..//output/preprocess/bulk_adata_f.h5ad')\n",
    "\n",
    "# adata = adata[:, adata.var_names.isin(df_collectri['target'].unique())]\n",
    "# gene_names = adata.var_names\n",
    "# adata.X = adata.layers['X_norm_pearson']\n",
    "# df = pd.DataFrame(adata.X, index=pd.MultiIndex.from_frame(adata.obs[['cell_type', 'sm_name', 'plate_name']]), columns=adata.var_names)\n",
    "# data = df.values\n",
    "\n",
    "gene_names = df.columns\n",
    "gene_name_dict = {gene_name: i for i, gene_name in enumerate(gene_names)}\n",
    "\n",
    "# Iterate over the edges (regulatory relationships)\n",
    "edge_idx = set()\n",
    "for gene_a, gene_b in zip(df_collectri['source'], df_collectri['target']):\n",
    "    if (gene_a not in gene_name_dict) or (gene_b not in gene_name_dict):\n",
    "        continue  # Consider only gene names that are present in the training data\n",
    "    i = gene_name_dict[gene_a]  # Index of first gene\n",
    "    j = gene_name_dict[gene_b]  # Index of second gene\n",
    "    edge_idx.add((i, j))\n",
    "edge_idx = np.asarray(list(edge_idx), dtype=int)\n",
    "\n",
    "# Convert list of edges into an adjacency matrix\n",
    "grn = np.zeros((len(gene_names), len(gene_names)))\n",
    "grn[edge_idx[:, 0], edge_idx[:, 1]] = 1\n",
    "# # Remove rows and columns with no annotation\n",
    "grn_idx = np.where(np.logical_or(grn.sum(axis=0) > 0, grn.sum(axis=1) > 0))[0]\n",
    "grn = grn[grn_idx, :][:, grn_idx]\n",
    "n_genes = len(grn_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:39:41.220222Z",
     "iopub.status.busy": "2024-05-24T10:39:41.219815Z",
     "iopub.status.idle": "2024-05-24T10:39:41.413891Z",
     "shell.execute_reply": "2024-05-24T10:39:41.413218Z",
     "shell.execute_reply.started": "2024-05-24T10:39:41.220194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grn_net = np.zeros((len(gene_names), len(gene_names)))\n",
    "for source, target, weight in zip(df_collectri['source'], df_collectri['target'], df_collectri['weight']):\n",
    "    if (source not in gene_name_dict) or (target not in gene_name_dict):\n",
    "        continue  # Consider only gene names that are present in the training data\n",
    "    i = gene_name_dict[source]  # Index of first gene\n",
    "    j = gene_name_dict[target]  # Index of second gene\n",
    "    grn_net[i,j] = weight\n",
    "# # Remove rows and columns with no annotation\n",
    "grn_idx = np.where(np.logical_or(grn_net.sum(axis=0) > 0, grn_net.sum(axis=1) > 0))[0]\n",
    "grn_net = grn_net[grn_idx, :][:, grn_idx]\n",
    "n_genes = len(grn_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:48:49.017778Z",
     "iopub.status.busy": "2024-05-24T10:48:49.017367Z",
     "iopub.status.idle": "2024-05-24T10:48:49.534380Z",
     "shell.execute_reply": "2024-05-24T10:48:49.533434Z",
     "shell.execute_reply.started": "2024-05-24T10:48:49.017750Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.det(torch.tensor(grn_net)+torch.eye(grn_net.shape[0])*.5)\n",
    "# grn_net[grn_net!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:50:52.975174Z",
     "iopub.status.busy": "2024-05-24T10:50:52.974731Z",
     "iopub.status.idle": "2024-05-24T10:50:52.983505Z",
     "shell.execute_reply": "2024-05-24T10:50:52.982648Z",
     "shell.execute_reply.started": "2024-05-24T10:50:52.975145Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, n_genes:int, n_nodes_latent:int=10000):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.n_genes = n_genes\n",
    "        # self.A  = nn.Parameter(.5*torch.eye(n_genes))\n",
    "        self.A = torch.tensor(grn_net, dtype=torch.float32, device='cuda', requires_grad=False)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_genes, 120),\n",
    "            nn.LeakyReLU(.2),\n",
    "            nn.Linear(120, 120),\n",
    "            nn.LeakyReLU(.2),\n",
    "            nn.Linear(120, n_genes))\n",
    "\n",
    "        self.mu_scaler = nn.Linear(n_genes, n_genes)\n",
    "        self.logvar_scaler = nn.Linear(n_genes, n_genes)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(n_genes, 120),\n",
    "            nn.LeakyReLU(.2),\n",
    "            nn.Linear(120, 120),\n",
    "            nn.LeakyReLU(.2),\n",
    "            nn.Linear(120, n_genes))\n",
    "        \n",
    "\n",
    "    def reparametrize(self, mu, log_var):\n",
    "        std = torch.sqrt(torch.exp(log_var))\n",
    "        eps = torch.randn_like(log_var)\n",
    "        # return mu + std*eps\n",
    "        return mu + log_var*eps\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu_scaler(x)\n",
    "        log_var = self.logvar_scaler(x)\n",
    "\n",
    "        # A = torch.eye(self.n_genes).to(device='cuda') - self.A.t()\n",
    "        A = self.A\n",
    "        mu = torch.matmul(mu, A)\n",
    "        # print(mu[0])\n",
    "        log_var = torch.matmul(log_var, A)\n",
    "\n",
    "        z = self.reparametrize(mu, log_var)\n",
    "        # A_inv = torch.linalg.inv(A)\n",
    "        # z = torch.matmul(z, A_inv)\n",
    "\n",
    "        x = self.decoder(z)\n",
    "        # print(x[0])\n",
    "        return x, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:50:55.698953Z",
     "iopub.status.busy": "2024-05-24T10:50:55.698370Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 1.162, R2:-0.156:   0%|          | 1/200 [00:04<15:04,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.524682849175731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 0.717, R2:0.287:   6%|▌         | 11/200 [00:12<05:17,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.524682849175731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 0.466, R2:0.536:  10%|█         | 21/200 [00:20<04:58,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.524682849175731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 0.392, R2:0.610:  16%|█▌        | 31/200 [00:29<04:54,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.524682849175731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 0.377, R2:0.624:  20%|██        | 41/200 [00:37<04:31,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.524682849175731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 0.363, R2:0.639:  26%|██▌       | 51/200 [00:47<04:36,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.524682849175731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 0.371, R2:0.630:  30%|███       | 61/200 [00:55<03:58,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.524682849175731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 0.403, R2:0.599:  36%|███▌      | 71/200 [01:04<03:44,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.524682849175731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rel loss: 0.403, R2:0.599:  40%|████      | 80/200 [01:10<01:46,  1.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39meye(n_genes, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     62\u001b[0m     grn_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(model\u001b[38;5;241m.\u001b[39mA\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUROC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrn_net\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrn_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     65\u001b[0m mean_rel_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(rel_loss_store)\n\u001b[1;32m     66\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(mean_rel_loss)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:639\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[0;32m--> 639\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_binarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    641\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    642\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:563\u001b[0m, in \u001b[0;36mlabel_binarize\u001b[0;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[1;32m    561\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(indices)\n\u001b[1;32m    562\u001b[0m     data\u001b[38;5;241m.\u001b[39mfill(pos_label)\n\u001b[0;32m--> 563\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsr_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    565\u001b[0m     Y \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_compressed.py:72\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     66\u001b[0m     idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_dtype((indices, indptr),\n\u001b[1;32m     67\u001b[0m                                 maxval\u001b[38;5;241m=\u001b[39mmaxval,\n\u001b[1;32m     68\u001b[0m                                 check_contents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(indices, copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m     71\u001b[0m                             dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO: dataloader = DataLoader(train_data, batch_size=self.opt.batch_size, shuffle=True, num_workers=1)\n",
    "#TODO: how to account for batch effects        \n",
    "train_data = data\n",
    "batch_size = 10\n",
    "n_epoch = 200\n",
    "# torch data\n",
    "train_data = torch.FloatTensor(train_data)\n",
    "if use_gpu:\n",
    "    train_data = train_data.cuda()\n",
    "\n",
    "model = NN(n_genes=n_genes)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "#TODO: loss function. cross entropy loss? other types  \n",
    "criterion = lambda Y_true, Y_pred: torch.sum(torch.square(Y_true-Y_pred))\n",
    "# optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=.00001, momentum=.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-7)\n",
    "\n",
    "# scheduler = torch.lr_scheduler.StepLR(optimizer, step_size=10, gamma=.1) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, \n",
    "            patience=5, threshold_mode='rel', threshold=0.0001, cooldown=5, min_lr=1e-10, eps=1e-8)\n",
    "\n",
    "pbar = tqdm.tqdm(range(n_epoch))\n",
    "for i_epoch in pbar:\n",
    "    # shuffle the data\n",
    "    train_data = train_data[torch.randperm(train_data.size(dim=0))]\n",
    "    # train for a epoch\n",
    "    model.train()\n",
    "    rel_loss_store = []\n",
    "    Y_pred_stack = []\n",
    "    Y_true_stack = []\n",
    "\n",
    "    for X in np.array_split(train_data, batch_size, axis=0):\n",
    "        X = X[:, grn_idx]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        Y_true = X #TODO: add noise to the data\n",
    "        Y_pred, mu, log_var = model.forward(X)\n",
    "\n",
    "        Y_true_stack.append(Y_true.cpu().detach().numpy())\n",
    "        Y_pred_stack.append(Y_pred.cpu().detach().numpy())\n",
    "        # calculate loss and backpropagate \n",
    "        loss_x = criterion(Y_true, Y_pred)\n",
    "        loss_KL =  - 0.5 * torch.sum(1.0 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        beta = 1\n",
    "        loss = loss_x + beta*loss_KL\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(loss_x)\n",
    "\n",
    "        # baseline pred\n",
    "        Y_pred_mean = torch.mean(Y_true, axis=0)\n",
    "        loss_baseline = criterion(Y_true, Y_pred_mean)\n",
    "        rel_loss = loss_x/loss_baseline\n",
    "        rel_loss_store.append(rel_loss.item())\n",
    "    if i_epoch%10==0:\n",
    "        # AUROC\n",
    "        mask = ~np.eye(n_genes, dtype=bool)\n",
    "        grn_pred = np.abs(model.A.cpu().data.numpy().T)\n",
    "        print('AUROC', roc_auc_score(np.abs(grn_net[mask]), grn_pred[mask]))\n",
    "        \n",
    "    mean_rel_loss = np.mean(rel_loss_store)\n",
    "    scheduler.step(mean_rel_loss)\n",
    "\n",
    "    y_pred = np.concatenate(Y_pred_stack, axis=0)\n",
    "    y_true = np.concatenate(Y_true_stack, axis=0)\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='variance_weighted')\n",
    "    \n",
    "    pbar.set_description(f'Rel loss: {mean_rel_loss:.3f}, R2:{r2:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.5146390800748502\n"
     ]
    }
   ],
   "source": [
    "model.A\n",
    "print('AUROC', roc_auc_score(np.abs(model.A.cpu().data.numpy().T[mask]), model.A.cpu().data.numpy()[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3494, 3494)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grn_net.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T17:45:29.685266Z",
     "iopub.status.busy": "2024-05-23T17:45:29.684863Z",
     "iopub.status.idle": "2024-05-23T17:45:29.703625Z",
     "shell.execute_reply": "2024-05-23T17:45:29.702865Z",
     "shell.execute_reply.started": "2024-05-23T17:45:29.685238Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 4.9868e-01, -7.2643e-04, -4.8510e-03,  ...,  2.6554e-03,\n",
       "         -1.0545e-03, -8.5110e-03],\n",
       "        [ 2.2719e-03,  5.1852e-01,  4.2199e-03,  ...,  2.1642e-03,\n",
       "         -1.4096e-04, -1.9116e-03],\n",
       "        [-2.2845e-04,  1.4502e-03,  5.1587e-01,  ..., -2.0177e-03,\n",
       "         -6.1622e-04, -9.3648e-04],\n",
       "        ...,\n",
       "        [-1.7440e-03, -2.0144e-03,  1.7241e-03,  ...,  5.0684e-01,\n",
       "         -5.1308e-04, -5.8981e-03],\n",
       "        [ 1.2055e-03, -5.6728e-03, -1.6025e-03,  ..., -3.2979e-04,\n",
       "          5.2474e-01, -9.3714e-04],\n",
       "        [-2.4000e-03, -1.1062e-03, -2.2459e-03,  ..., -1.1234e-03,\n",
       "          1.1746e-03,  5.1869e-01]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
