{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pereggrn_perturbations\n",
    "import pereggrn_networks\n",
    "\n",
    "import os \n",
    "import anndata as ad \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import scanpy as sc\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "task_grn_inference_dir = '../../task_grn_inference'\n",
    "pereggrn_dir = \"../../pereggrn\"\n",
    "\n",
    "sys.path.append(task_grn_inference_dir)\n",
    "# from src.helper import *\n",
    "# from src.exp_analysis.helper import *\n",
    "from src.utils.util import process_links\n",
    "pereggrn_perturbations.set_data_path(f\"{pereggrn_dir}/perturbation_data/perturbations\")\n",
    "\n",
    "\n",
    "\n",
    "inference_data_dir = f'{task_grn_inference_dir}/resources/inference_data/'\n",
    "evaluation_data_dir = f'{task_grn_inference_dir}/resources/evaluation_data/'\n",
    "raw_datasets_dir = f'{task_grn_inference_dir}/resources/datasets_raw/'\n",
    "\n",
    "# os.makedirs(inference_data_dir, exist_ok=True)\n",
    "# os.makedirs(evaluation_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # get global models\n",
    "    par = {\n",
    "        'global_models': [\n",
    "                            'ANANSE_tissue/networks/lung.parquet',\n",
    "                            'ANANSE_tissue/networks/stomach.parquet', \n",
    "                            'ANANSE_tissue/networks/heart.parquet',\n",
    "                            'ANANSE_tissue/networks/bone_marrow.parquet',\n",
    "                            \n",
    "                            'gtex_rna/networks/Whole_Blood.parquet',\n",
    "                            'gtex_rna/networks/Brain_Amygdala.parquet', \n",
    "                            'gtex_rna/networks/Breast_Mammary_Tissue.parquet', \n",
    "                            'gtex_rna/networks/Lung.parquet',\n",
    "                            'gtex_rna/networks/Stomach.parquet',\n",
    "\n",
    "                            'cellnet_human_Hg1332/networks/bcell.parquet',\n",
    "                            'cellnet_human_Hg1332/networks/tcell.parquet',\n",
    "                            'cellnet_human_Hg1332/networks/skin.parquet',\n",
    "                            'cellnet_human_Hg1332/networks/neuron.parquet',\n",
    "                            'cellnet_human_Hg1332/networks/heart.parquet',\n",
    "                            ],\n",
    "        'read_dir': f'{pereggrn_dir}/network_collection/networks/',\n",
    "        'write_dir': f'{task_grn_inference_dir}/resources/grn_models/global/',\n",
    "        'max_n_links': 50_000\n",
    "    }\n",
    "    os.makedirs(par['write_dir'], exist_ok=True)\n",
    "\n",
    "    names = []\n",
    "    for model in par['global_models']:\n",
    "        net = pd.read_parquet(f\"{par['read_dir']}/{model}\")\n",
    "        net.columns = ['source','target','weight']\n",
    "        method = model.split('/')[0].split('_')[0].capitalize()\n",
    "        tissue = model.split('/')[-1].split('.')[0].replace('_', ' ').capitalize()\n",
    "        name = method+':'+tissue\n",
    "\n",
    "        net = process_links(net, par)\n",
    "\n",
    "\n",
    "        net.to_csv(f\"{par['write_dir']}/{name}.csv\")\n",
    "\n",
    "        names.append(name)\n",
    "    names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psedudobulk_fun(adata):\n",
    "    # control_perturbs = adata.obs[adata.obs['is_control']]['perturbation'].unique()\n",
    "    # test_perturbs = adata.obs[adata.obs['is_test']]['perturbation'].unique()\n",
    "\n",
    "    # Aggregate metadata (mean or mode as appropriate)\n",
    "    metadata = (\n",
    "        adata.obs.groupby('perturbation')\n",
    "        .agg(lambda x: x.mode()[0] if x.nunique() == 1 else x.iloc[0])  # Adjust for categorical columns\n",
    "    )\n",
    "\n",
    "    # if 'counts' in adata.layers:\n",
    "    #     adata.X = adata.layers['counts'].copy()\n",
    "\n",
    "    # Pseudobulk the main layer\n",
    "    pseudobulk_data = adata.to_df().groupby(adata.obs['perturbation']).sum()\n",
    "    # Ensure the metadata index matches pseudobulk counts\n",
    "    metadata = metadata.loc[pseudobulk_data.index]\n",
    "\n",
    "    # Create a new AnnData object for pseudobulked data\n",
    "    adata_bulked = sc.AnnData(\n",
    "            X=pseudobulk_data.values,\n",
    "            obs=metadata.reset_index(),\n",
    "            var=adata.var.copy()\n",
    "        )\n",
    "\n",
    "    # if 'counts' in adata.layers:\n",
    "    #     # Add pseudobulked layers\n",
    "    #     adata_bulked.layers['counts'] = csr_matrix(adata_bulked.X)\n",
    "    #     adata_bulked.layers['X_norm'] = sc.experimental.pp.normalize_pearson_residuals(adata_bulked, layer='counts', inplace=False)['X']\n",
    "    #     mask = ~(adata_bulked.X.std(axis=0)==0)\n",
    "    #     adata_bulked = adata_bulked[:, mask]\n",
    "    #     lognorm = sc.pp.normalize_total(adata_bulked, layer='counts', inplace=False)['X']\n",
    "    #     adata_bulked.layers['lognorm'] = sc.pp.log1p(lognorm, copy=True)\n",
    "    # else:\n",
    "    #     adata_bulked.layers['X_norm'] = adata_bulked.X.copy()\n",
    "    # adata_bulked.layers['X_norm'] = adata_bulked.X.copy()\n",
    "        \n",
    "    return adata_bulked\n",
    "# - make data sparse\n",
    "# def sparsify(adata):\n",
    "#     if (not isinstance(adata.X, csr_matrix)):\n",
    "#         adata.X = csr_matrix(adata.X) \n",
    "#     if (not isinstance(adata.layers['counts'], csr_matrix)):\n",
    "#         adata.layers['counts'] = csr_matrix(adata.layers['counts']) \n",
    "#     return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gene metadata...\n",
      "Checking perturbation labels...\n",
      "Checking control labels...\n",
      "Checking which genes are measured...\n",
      "Checking for log-transform and raw data...\n",
      "... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1878279867.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  adata.obs.groupby('perturbation')\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1878279867.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  pseudobulk_data = adata.to_df().groupby(adata.obs['perturbation']).sum()\n",
      "/home/jnourisa/miniconda3/envs/pereggrn/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1545414315.py:67: ImplicitModificationWarning: Setting element `.layers['X_norm']` of view, initializing view as actual.\n",
      "  adata_train.layers['X_norm'] = adata_train.X\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1545414315.py:68: ImplicitModificationWarning: Setting element `.layers['X_norm']` of view, initializing view as actual.\n",
      "  adata_test.layers['X_norm'] = adata_test.X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gene metadata...\n",
      "Checking perturbation labels...\n",
      "Checking control labels...\n",
      "Checking which genes are measured...\n",
      "Checking for log-transform and raw data...\n",
      "... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1545414315.py:67: ImplicitModificationWarning: Setting element `.layers['X_norm']` of view, initializing view as actual.\n",
      "  adata_train.layers['X_norm'] = adata_train.X\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1545414315.py:68: ImplicitModificationWarning: Setting element `.layers['X_norm']` of view, initializing view as actual.\n",
      "  adata_test.layers['X_norm'] = adata_test.X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gene metadata...\n",
      "Checking perturbation labels...\n",
      "Checking control labels...\n",
      "Checking which genes are measured...\n",
      "Checking for log-transform and raw data...\n",
      "... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnourisa/miniconda3/envs/pereggrn/lib/python3.10/site-packages/anndata/_core/anndata.py:747: UserWarning: \n",
      "AnnData expects .var.index to contain strings, but got values like:\n",
      "    ['LINC01409', 'LINC01128', 'NOC2L', 'KLHL17', 'HES4']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  value_idx = self._prep_dim_index(value.index, attr)\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1545414315.py:67: ImplicitModificationWarning: Setting element `.layers['X_norm']` of view, initializing view as actual.\n",
      "  adata_train.layers['X_norm'] = adata_train.X\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1545414315.py:68: ImplicitModificationWarning: Setting element `.layers['X_norm']` of view, initializing view as actual.\n",
      "  adata_test.layers['X_norm'] = adata_test.X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gene metadata...\n",
      "Checking perturbation labels...\n",
      "Checking control labels...\n",
      "Checking which genes are measured...\n",
      "Checking for log-transform and raw data...\n",
      "... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnourisa/miniconda3/envs/pereggrn/lib/python3.10/site-packages/anndata/_core/anndata.py:747: UserWarning: \n",
      "AnnData expects .var.index to contain strings, but got values like:\n",
      "    ['RP11-34P13.8', 'RP11-54O7.3', 'SAMD11', 'PERM1', 'HES4']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  value_idx = self._prep_dim_index(value.index, attr)\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1878279867.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  adata.obs.groupby('perturbation')\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1878279867.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  pseudobulk_data = adata.to_df().groupby(adata.obs['perturbation']).sum()\n",
      "/home/jnourisa/miniconda3/envs/pereggrn/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1545414315.py:67: ImplicitModificationWarning: Setting element `.layers['X_norm']` of view, initializing view as actual.\n",
      "  adata_train.layers['X_norm'] = adata_train.X\n",
      "/vol/tmp/users/jnourisa/ipykernel_3576418/1545414315.py:68: ImplicitModificationWarning: Setting element `.layers['X_norm']` of view, initializing view as actual.\n",
      "  adata_test.layers['X_norm'] = adata_test.X\n"
     ]
    }
   ],
   "source": [
    "def process_all(file_name):\n",
    "    # - get the data\n",
    "    pereggrn_perturbations.load_perturbation_metadata()\n",
    "    adata = pereggrn_perturbations.load_perturbation(file_name) \n",
    "    # print(file_name,type(adata.X), adata.X[:5])\n",
    "    # return\n",
    "    pereggrn_perturbations.check_perturbation_dataset(ad = adata)\n",
    "\n",
    "    # - clearn up \n",
    "    del adata.obsp \n",
    "    del adata.varm\n",
    "    del adata.uns\n",
    "    del adata.obsm\n",
    "    if 'gene_name' in adata.var.columns:\n",
    "        adata.var = adata.var[['gene_name']]\n",
    "        adata.var = adata.var.set_index('gene_name')\n",
    "    else:\n",
    "        adata.var = adata.var[[]]\n",
    "    adata.obs = adata.obs[['perturbation', 'is_control', 'perturbation_type']]\n",
    "\n",
    "    # - data split \n",
    "    if file_name == 'replogle2':\n",
    "        ctr_samples = adata.obs.is_control\n",
    "        samples = adata.obs.index[~ctr_samples] \n",
    "        _, test_samples = train_test_split(samples, test_size=.2, random_state=32)\n",
    "        adata.obs['is_test'] = adata.obs.index.isin(test_samples)\n",
    "    elif file_name == 'norman':\n",
    "        ctr_samples = adata.obs.is_control\n",
    "        samples = adata[adata.obs.index[~ctr_samples]].obs.perturbation.unique()\n",
    "        _, test_samples = train_test_split(samples, test_size=.5, random_state=32)\n",
    "        adata.obs['is_test'] = adata.obs.perturbation.isin(test_samples)\n",
    "    elif file_name == 'nakatake':\n",
    "        samples = adata.obs.perturbation.unique()\n",
    "        _, test_samples = train_test_split(samples, test_size=.5, random_state=32)\n",
    "        adata.obs['is_test'] = adata.obs.perturbation.isin(test_samples)\n",
    "    elif file_name == 'adamson':\n",
    "        ctr_samples = adata.obs.is_control\n",
    "        samples = adata[adata.obs.index[~ctr_samples]].obs.perturbation.unique()\n",
    "        _, test_samples = train_test_split(samples, test_size=.8, random_state=32)\n",
    "        adata.obs['is_test'] = adata.obs.perturbation.isin(test_samples)\n",
    "\n",
    "    adata_train = adata[~adata.obs['is_test']] # we use single cells for train (if not already bulked)\n",
    "    \n",
    "    if file_name in ['norman', 'adamson']: # these two are single cells. for norman, we have .counts but not for adamson -> different preprocessing\n",
    "        adata_bulked = psedudobulk_fun(adata) # also normalize\n",
    "    else:\n",
    "        adata_bulked = adata\n",
    "        # adata_bulked.layers['X_norm'] = adata_bulked.X.copy()\n",
    "\n",
    "    adata_test = adata_bulked[adata_bulked.obs['is_test']] # we use bulked data for test \n",
    "\n",
    "\n",
    "    # - duplicated gene names\n",
    "    duplicates = adata_train.var_names[adata_train.var_names.duplicated()].unique()\n",
    "    adata_train = adata_train[:, ~adata_train.var_names.isin(duplicates)]\n",
    "\n",
    "    duplicates = adata_test.var_names[adata_test.var_names.duplicated()].unique()\n",
    "    adata_test = adata_test[:, ~adata_test.var_names.isin(duplicates)]\n",
    "\n",
    "    \n",
    "    # - normalize adata_train \n",
    "    # if file_name in ['norman']: # only norman needs this. the others are normalized already\n",
    "    #     lognorm = sc.pp.normalize_total(adata_train, layer='counts', inplace=False)['X']\n",
    "    #     adata_train.layers['X_norm'] = sc.pp.log1p(lognorm, copy=True)\n",
    "    # if file_name in ['adamson']: \n",
    "    #     adata_train.layers['X_norm'] = adata_train.X\n",
    "    adata_train.layers['X_norm'] = adata_train.X\n",
    "    adata_test.layers['X_norm'] = adata_test.X\n",
    "    adata.layers['X_norm'] = adata.X\n",
    "\n",
    "    # if file_name in ['norman']:\n",
    "    #     adata = sparsify(adata)    \n",
    "    #     adata_train = sparsify(adata_train)\n",
    "\n",
    "    if file_name in ['norman', 'adamson']:\n",
    "        adata.write(f'{raw_datasets_dir}/{file_name}_sc_counts.h5ad')\n",
    "        # adata_test_sc = adata[adata.obs['is_test']] # we also store singe cell data for these two datasets -> for WS distance\n",
    "        # duplicates = adata_test_sc.var_names[adata_test_sc.var_names.duplicated()].unique()\n",
    "        # adata_test_sc = adata_test_sc[:, ~adata_test_sc.var_names.isin(duplicates)]\n",
    "        # if 'X_norm' not in adata_test_sc.layers:\n",
    "        #     if 'counts' in adata_test_sc.layers:\n",
    "        #         lognorm = sc.pp.normalize_total(adata_test_sc, layer='counts', inplace=False)['X']\n",
    "        #         adata_test_sc.layers['X_norm'] = sc.pp.log1p(lognorm, copy=True)\n",
    "        #     else:\n",
    "        #         adata_test_sc.layers['X_norm'] = adata_test_sc.X\n",
    "        # adata_test_sc.write(f'{evaluation_data_dir}/{file_name}_perturbation_sc.h5ad')\n",
    "    # if file_name == 'replogle2':\n",
    "    #     file_name == 'replogle':\n",
    "    adata_bulked.write(f'{raw_datasets_dir}/{file_name}_bulked.h5ad')\n",
    "    adata_train.write(f'{inference_data_dir}/{file_name}_rna.h5ad')\n",
    "    adata_test.write(f'{evaluation_data_dir}/{file_name}_perturbation.h5ad')\n",
    "    \n",
    "    return adata_train \n",
    "\n",
    "for file_name in ['adamson', \"nakatake\", \"replogle2\", \"norman\"]:\n",
    "    adata = process_all(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
