{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-16T17:59:19.072466Z","iopub.status.busy":"2024-02-16T17:59:19.072017Z","iopub.status.idle":"2024-02-16T17:59:19.078708Z","shell.execute_reply":"2024-02-16T17:59:19.077530Z","shell.execute_reply.started":"2024-02-16T17:59:19.072436Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","import tqdm\n","import anndata\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch\n","from sklearn.metrics import matthews_corrcoef, roc_auc_score"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T16:00:12.376152Z","iopub.status.busy":"2024-02-16T16:00:12.375301Z","iopub.status.idle":"2024-02-16T16:00:26.716384Z","shell.execute_reply":"2024-02-16T16:00:26.715197Z","shell.execute_reply.started":"2024-02-16T16:00:12.376108Z"},"trusted":true},"outputs":[],"source":["adata_rna = anndata.read_h5ad('../output/scRNA/adata_rna.h5ad')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T17:03:52.442879Z","iopub.status.busy":"2024-02-16T17:03:52.442412Z","iopub.status.idle":"2024-02-16T17:03:52.450423Z","shell.execute_reply":"2024-02-16T17:03:52.449322Z","shell.execute_reply.started":"2024-02-16T17:03:52.442846Z"},"trusted":true},"outputs":[{"data":{"text/plain":["AnnData object with n_obs × n_vars = 25034 × 22778\n","    obs: 'cell_type', 'donor_id', 'cell_type_original', 'Donor', 'Cell type'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["adata_rna"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T17:20:27.338676Z","iopub.status.busy":"2024-02-16T17:20:27.337812Z","iopub.status.idle":"2024-02-16T17:20:27.356074Z","shell.execute_reply":"2024-02-16T17:20:27.354587Z","shell.execute_reply.started":"2024-02-16T17:20:27.338633Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['A1BG', 'A1BG-AS1', 'A2M', ..., 'ZYG11B', 'ZYX', 'ZZEF1'],\n","      dtype=object)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["gene_names = adata_rna.var.index.to_numpy()\n","gene_name_dict = {gene_name: i for i, gene_name in enumerate(gene_names)}\n","gene_names"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T17:41:58.988976Z","iopub.status.busy":"2024-02-16T17:41:58.988584Z","iopub.status.idle":"2024-02-16T17:42:01.973224Z","shell.execute_reply":"2024-02-16T17:42:01.971878Z","shell.execute_reply.started":"2024-02-16T17:41:58.988946Z"},"trusted":true},"outputs":[],"source":["# Download GRN\n","df_collectri = pd.read_csv(\"https://github.com/pablormier/omnipath-static/raw/main/op/collectri-26.09.2023.zip\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["\n","# Iterate over the edges (regulatory relationships)\n","edge_idx = set()\n","for gene_a, gene_b in zip(df_collectri['source'], df_collectri['target']):\n","    if (gene_a not in gene_name_dict) or (gene_b not in gene_name_dict):\n","        continue  # Consider only gene names that are present in the training data\n","    i = gene_name_dict[gene_a]  # Index of first gene\n","    j = gene_name_dict[gene_b]  # Index of second gene\n","    edge_idx.add((i, j))\n","edge_idx = np.asarray(list(edge_idx), dtype=int)\n","\n","# Convert list of edges into an adjacency matrix\n","grn = np.zeros((len(gene_names), len(gene_names)))\n","grn[edge_idx[:, 0], edge_idx[:, 1]] = 1\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["(5333, 5333)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["(grn==0).sum()/grn.size\n","grn.shape"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Remove rows and columns with no annotation\n","grn_idx = np.where(np.logical_or(grn.sum(axis=0) > 0, grn.sum(axis=1) > 0))[0]\n","grn = grn[grn_idx, :][:, grn_idx]"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T17:43:28.138718Z","iopub.status.busy":"2024-02-16T17:43:28.138146Z","iopub.status.idle":"2024-02-16T17:43:28.157501Z","shell.execute_reply":"2024-02-16T17:43:28.155931Z","shell.execute_reply.started":"2024-02-16T17:43:28.138677Z"},"trusted":true},"outputs":[],"source":["class Scaler(torch.nn.Module):\n","    \n","    def __init__(self, m: int) -> None:\n","        torch.nn.Module.__init__(self)\n","        self.m: int = m\n","        self.a: torch.Tensor = torch.nn.Parameter(torch.ones((1, self.m)))\n","        self.b: torch.Tensor = torch.nn.Parameter(torch.zeros((1, self.m)))\n","    \n","    def forward(self, X: torch.Tensor) -> torch.Tensor:\n","        return self.a * X + self.b\n","\n","\n","class VAE(torch.nn.Module):\n","    \n","    def __init__(self, n_genes: int) -> None:\n","        torch.nn.Module.__init__(self)\n","        self.n_genes: int = n_genes\n","        self.A = torch.nn.Parameter(0.5 * torch.eye(n_genes).float())\n","        # self.A = 0.5 * torch.eye(n_genes).float()\n","        \n","        self.encoder = torch.nn.Sequential(\n","            Scaler(self.n_genes),\n","            torch.nn.LeakyReLU(),\n","            Scaler(self.n_genes),\n","            torch.nn.LeakyReLU(),\n","        )\n","        \n","        self.mu_regressor = torch.nn.Sequential(\n","            Scaler(self.n_genes)\n","        )\n","        self.logvar_regressor = torch.nn.Sequential(\n","            Scaler(self.n_genes)\n","        )\n","        \n","        self.decoder = torch.nn.Sequential(\n","            Scaler(self.n_genes),\n","            torch.nn.LeakyReLU(),\n","            Scaler(self.n_genes)\n","        )\n","    \n","    def reparametrize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n","        if self.training:\n","            std = torch.sqrt(torch.exp(logvar) + 1e-10)\n","            return std * torch.randn_like(mu) + mu\n","        else:\n","            return mu\n","    \n","    def forward(self, X_rna: torch.Tensor) -> torch.Tensor:        \n","        encoded_rna = self.encoder(X_rna)\n","        \n","        mu = self.mu_regressor(encoded_rna)\n","        logvar = self.logvar_regressor(encoded_rna)\n","        \n","        grn = torch.eye(self.n_genes) - self.A.t()  # TODO: transpose\n","        mu = torch.matmul(mu, grn)\n","        logvar = torch.matmul(logvar, grn)\n","        \n","        Z = self.reparametrize(mu, logvar)\n","        \n","        grn_inv = torch.linalg.inv(grn)\n","        Z = torch.matmul(Z, grn_inv)\n","        \n","        decoded_rna = self.decoder(Z)\n","        \n","        return decoded_rna, mu, logvar\n","n_genes = len(grn_idx)\n","n_epochs = 10\n","\n","vae = VAE(n_genes)\n","vae.train()\n","\n","batch_size = 256\n","\n","optimizer = torch.optim.SGD(vae.parameters(), lr=1e-3, weight_decay=1e-6)\n","# TODO: Adam?\n","\n","losses = []\n","\n","for epoch in range(n_epochs):\n","    losses.append(0)\n","    n_batches = 0\n","    \n","    idx = np.arange(len(adata_rna))\n","    np.random.shuffle(idx)\n","\n","    for batch_idx in tqdm.tqdm(np.array_split(idx, int(len(idx) / batch_size)), desc=f'Epoch {epoch + 1}'):\n","        \n","        x_rna = torch.FloatTensor(adata_rna[batch_idx, grn_idx].X.todense())\n","        \n","        # Reset gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        decoded, mu, logvar = vae(x_rna)\n","        \n","        # Compute loss\n","        reconstruction_loss = torch.sum(torch.square(x_rna - decoded))\n","        kld = 0.5 * torch.sum(1.0 + logvar - mu.pow(2) - logvar.exp())\n","        loss = reconstruction_loss - kld\n","        loss = loss / (len(batch_idx) * n_genes)\n","        \n","        # Backward pass\n","        loss.backward()\n","        \n","        # Update parameters\n","        optimizer.step()\n","\n","        # Update total loss\n","        losses[-1] += loss.item()\n","        n_batches += 1\n","        \n","        mask = ~np.eye(n_genes, dtype=bool)\n","        grn_pred = np.abs(vae.A.cpu().data.numpy().T)\n","        print('AUROC', roc_auc_score(grn[mask], grn_pred[mask]))\n","        print('Loss', loss.item())\n","\n","    losses[-1] /= n_batches\n","    print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, n_epochs, losses[-1]))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["(5333,)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["grn_idx.shape"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4451166,"sourceId":7637876,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
