{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_encoder_legecy:\n",
    "    def __init__(self, df_main, n_components=35, shares={\n",
    "                                        'sm_name':{'de_x':35},\n",
    "                                        'cell_type': {'de_x':6}\n",
    "                                        },\n",
    "                                        te_params = dict(min_samples_leaf=20, smoothing=100),\n",
    "                                        grn_model=None\n",
    "                                        ):  \n",
    "        # target df to encode\n",
    "        self.df_main = df_main\n",
    "        self.grn_model = grn_model\n",
    "        # regressor\n",
    "        self.emb_model = RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
    "        # reducer\n",
    "        self.reducer = TruncatedSVD(n_components=n_components, n_iter=12, random_state=random_state)\n",
    "        self.Y = self.reducer.fit_transform(df_main)\n",
    "        # encoder \n",
    "        self.enc = ce.TargetEncoder(**te_params) #[0, 0.05, 0.5, 0.1,0.9,10]\n",
    "        # encode data\n",
    "        var_x_name = list(shares['sm_name'].keys())[0]\n",
    "        n_components = shares['sm_name'][var_x_name]\n",
    "        y_sm_name = self.create_feature_space(self.df_main, var_x=var_x_name, n=n_components)\n",
    "        \n",
    "        # cell type\n",
    "        var_x_name = list(shares['cell_type'].keys())[0]\n",
    "        n_components = shares['cell_type'][var_x_name]\n",
    "        y_cell_type = self.create_feature_space(self.df_main, var_x=var_x_name, n=n_components)\n",
    "        # the order is important\n",
    "        self.emb_data = {'sm_name':y_sm_name, 'cell_type': y_cell_type}\n",
    "        self.determine_X()\n",
    "        print(self.X.shape, self.X_submit.shape)\n",
    "\n",
    "    def determine_X(self):\n",
    "        for i, (name, y) in enumerate(self.emb_data.items()):\n",
    "            for i_target in tqdm.tqdm(range(y.shape[1])):\n",
    "                if i_target == 0:\n",
    "                    X_encoded = self.enc.fit_transform(self.df_main.reset_index()[name], y[:,i_target])\n",
    "                    X_submit_encoded = self.enc.transform(id_map.reset_index()[name])\n",
    "                else:\n",
    "                    X_encoded_tmp = self.enc.fit_transform(self.df_main.reset_index()[name], y[:,i_target])\n",
    "                    X_encoded = np.concatenate( [X_encoded, X_encoded_tmp], axis = 1)\n",
    "                    X_encoded_tmp = self.enc.transform(id_map.reset_index()[name])\n",
    "                    X_submit_encoded = np.concatenate([X_submit_encoded, X_encoded_tmp], axis = 1)\n",
    "            if i == 0:\n",
    "                X = X_encoded\n",
    "                X_submit = X_submit_encoded\n",
    "            else:\n",
    "                X = np.concatenate([X, X_encoded], axis = 1)\n",
    "                X_submit = np.concatenate([X_submit, X_submit_encoded], axis = 1)\n",
    "\n",
    "        self.X = X\n",
    "        self.X_submit = X_submit\n",
    "    def create_feature_space(self, df_to_encode, var_x='sm_name', n=35):\n",
    "        \n",
    "        if var_x == 'de_x':\n",
    "            return TruncatedSVD(n_components=n, n_iter=12, random_state=random_state).fit_transform(df_to_encode.values)\n",
    "\n",
    "        elif var_x == 'tf_x':\n",
    "            df_main_c = df_to_encode.copy()\n",
    "            net = self.grn_model\n",
    "            tf_act = enrich_tfs(df_main_c, net)\n",
    "\n",
    "            tf_act = TruncatedSVD(n_components=n, n_iter=12, random_state=random_state).fit_transform(tf_act)\n",
    "            return tf_act\n",
    "        raise ValueError('define feature space')\n",
    "    def validate(self, mask_tr, mask_va):\n",
    "        # print(mask_tr)\n",
    "        X_tr, Y_tr = self.X[mask_tr,:], self.Y[mask_tr,:]\n",
    "        X_va = self.X[mask_va,:]\n",
    "        self.emb_model.fit(X_tr, Y_tr)\n",
    "        return self.reducer.inverse_transform(self.emb_model.predict(X_va))\n",
    "    def calculate_y_submit(self):\n",
    "        self.emb_model.fit(self.X, self.Y)\n",
    "        return self.reducer.inverse_transform(self.emb_model.predict(self.X_submit))\n",
    "\n",
    "class model_encoder:\n",
    "    def __init__(self, df_main, n_components_y=35, \n",
    "                 n_highlyvarible_tfs = 100,\n",
    "                    te_params = dict(min_samples_leaf=20, smoothing=100),\n",
    "                    grn_model=None\n",
    "                    ):  \n",
    "        # target df to encode\n",
    "        self.n_highlyvarible_tfs = n_highlyvarible_tfs\n",
    "        self.df_main = df_main\n",
    "        self.grn_model = grn_model\n",
    "        # regressor\n",
    "        self.emb_model = RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
    "        # reducer\n",
    "        self.reducer = TruncatedSVD(n_components=n_components_y, n_iter=12, random_state=random_state)\n",
    "        self.Y = self.reducer.fit_transform(df_main)\n",
    "        # encoder \n",
    "        self.enc = ce.TargetEncoder(**te_params) #[0, 0.05, 0.5, 0.1,0.9,10]\n",
    "        # encode data\n",
    "        self.emb_data = self.create_feature_space(self.df_main)\n",
    "        self.determine_X()\n",
    "        print(self.X.shape)\n",
    "    def determine_X(self):\n",
    "        features = self.df_main.index.names\n",
    "        feature_x = self.emb_data\n",
    "        hot_encoding_features = [feature for feature in features if (feature != 'sm_name')]\n",
    "        encoder = OneHotEncoder()\n",
    "        for i, feature in tqdm.tqdm(enumerate(hot_encoding_features)):\n",
    "            X_encoded = encoder.fit_transform(self.df_main.reset_index()[feature].values.reshape(-1,1)).toarray()\n",
    "            X_submit_encoded = encoder.transform(id_map[feature].values.reshape(-1,1)).toarray()\n",
    "            # print(X_encoded)\n",
    "            # aa\n",
    "            if i == 0:\n",
    "                X = X_encoded\n",
    "                X_submit = X_submit_encoded\n",
    "            else:\n",
    "                X = np.concatenate([X, X_encoded], axis = 1)\n",
    "                X_submit = np.concatenate([X_submit, X_submit_encoded], axis = 1)\n",
    "        n_components_sm_name = 100\n",
    "        n_components_sm_name = min([n_components_sm_name, feature_x.shape[1]])\n",
    "        for i_target in tqdm.tqdm(range(n_components_sm_name)):\n",
    "            if i_target == 0:\n",
    "                # print(feature_x[:,i_target])\n",
    "                X_encoded = self.enc.fit_transform(self.df_main.reset_index()['sm_name'], feature_x[:,i_target])\n",
    "                X_submit_encoded = self.enc.transform(id_map.reset_index()['sm_name'])\n",
    "            else:\n",
    "                X_encoded_tmp = self.enc.fit_transform(self.df_main.reset_index()['sm_name'], feature_x[:,i_target])\n",
    "                X_encoded = np.concatenate( [X_encoded, X_encoded_tmp], axis = 1)\n",
    "                X_encoded_tmp = self.enc.transform(id_map.reset_index()['sm_name'])\n",
    "                X_submit_encoded = np.concatenate([X_submit_encoded, X_encoded_tmp], axis = 1)\n",
    "        X = np.concatenate([X, X_encoded], axis = 1)\n",
    "        X_submit = np.concatenate([X_submit, X_submit_encoded], axis = 1)\n",
    "        self.X = X\n",
    "        self.X_submit = X_submit\n",
    "    def calculate_y_submit(self):\n",
    "        self.emb_model.fit(self.X, self.Y)\n",
    "        return self.reducer.inverse_transform(self.emb_model.predict(self.X_submit))\n",
    "    def create_feature_space(self, df_to_encode):\n",
    "        if self.grn_model is None:\n",
    "            n = 50\n",
    "            return TruncatedSVD(n_components=n, n_iter=12, random_state=random_state).fit_transform(df_to_encode.values)\n",
    "        else:\n",
    "            n = self.n_highlyvarible_tfs\n",
    "            df_main_c = df_to_encode.copy()\n",
    "            net = self.grn_model\n",
    "            tf_act = enrich_tfs(df_main_c, net)\n",
    "            # tf_act = TruncatedSVD(n_components=n, n_iter=12, random_state=random_state).fit_transform(tf_act)\n",
    "            variances = tf_act.var()\n",
    "            sorted_variances = variances.sort_values(ascending=False)\n",
    "            top_tfs = sorted_variances.head(n).index.tolist()\n",
    "            tf_act = tf_act[top_tfs].values\n",
    "            return tf_act\n",
    "        raise ValueError('define feature space')\n",
    "    def validate(self, mask_tr, mask_va):\n",
    "        X_tr, Y_tr = self.X[mask_tr,:], self.Y[mask_tr,:]\n",
    "        X_va = self.X[mask_va,:]\n",
    "        self.emb_model.fit(X_tr, Y_tr)\n",
    "        return self.reducer.inverse_transform(self.emb_model.predict(X_va))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
